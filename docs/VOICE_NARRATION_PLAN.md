# תוכנית יישום: הקראה בזמן אמת של מסלולי טיול (Live Voice Narration)

מסמך זה מתאר את הארכיטקטורה והצעדים הנדרשים להוספת יכולת הקראה קולית בזמן אמת לאפליקציית Urbanito.

## 1. מטרת העל
לאפשר למשתמש המטייל במסלול לשמוע הסברים קוליים ("הדרכה") על נקודות עניין (POIs) באופן אוטומטי או יזום כשהוא מתקרב אליהן, תוך שימוש במנועי AI להפקת דיבור טבעי ואיכותי בעברית ובאנגלית.

## 2. ארכיטקטורה טכנית

### א. תשתית הקול (Voice Infrastructure)
*   **מנוע TTS (Text-to-Speech):** שימוש ב-`Gemini 2.5 Flash TTS` (כבר קיים ב-`geminiService.ts`) או שדרוג ל-ElevenLabs לאיכות גבוהה יותר אם יידרש.
*   **ניהול AudioContext:** יצירת `AudioProvider` מרכזי ב-React שינהל את ניגון האודיו, תורים (Queuing), ושמירה על רציפות (למנוע חפיפה בין הסברים).
*   **התמודדות עם מגבלות דפדפן:** טיפול במדיניות Auto-play (נדרשת אינטראקציה ראשונית מהמשתמש כדי לאפשר ניגון אוטומטי בהמשך).

### ב. לוגיקת מיקום (Geolocation Logic)
*   ניטור מיקום המשתמש ברקע (באמצעות `navigator.geolocation.watchPosition` או הוק קיים).
*   **חישוב קרבה (Proximity Detection):** בדיקה רציפה האם המשתמש נמצא ברדיוס "הפעלה" (למשל, 30 מטר) מנקודת עניין שטרם הושמעה.
*   **מנגנון Trigger:**
    *   *אוטומטי:* התחלת ניגון כשנכנסים לרדיוס.
    *   *ידני:* הקפצת Toast/התראה ("אתה קרוב ל[שם המקום] - רוצה לשמוע?") למניעת הפרעה.

### ג. ניהול תוכן (Content Management)
*   **Pre-fetching:** יצירת קבצי השמע (או ה-ArrayBuffer) מראש עבור הנקודות הקרובות במסלול, כדי למנוע השהייה (Latency) ברגע ההגעה לנקודה.
*   **Caching:** שמירת קבצי השמע בזיכרון המכשיר (IndexedDB או Cache API) כדי לחסוך קריאות API חוזרות.

## 3. רכיבי ממשק משתמש (UI Components)

1.  **Audio Player Floating Bar:**
    *   נגן צף המופיע בתחתית המסך בזמן ניווט פעיל.
    *   כפתורי שליטה: Play/Pause, Skip, Replay.
    *   חיווי ויזואלי (Waveform או Progress bar).
2.  **Map Markers:**
    *   סימון ויזואלי על המפה לנקודות שיש להן אודיו זמין / כבר הושמעו.

## 4. תוכנית עבודה (Implementation Steps)

### שלב 1: תשתית (Infrastructure)
1.  יצירת `AudioContext` ב-React (`AudioProvider`).
2.  מימוש פונקציונליות בסיסית של תור ניגון (Queue).
3.  בדיקת היתכנות טכנית של `generateSpeech` הקיים ומיקומו ב-flow.

### שלב 2: לוגיקת טריגרים (Trigger Logic)
1.  חיבור ל-Hook של המיקום.
2.  כתיבת האלגוריתם לזיהוי כניסה למתחם POI.
3.  ניהול סטייט של "נקודות שהושמעו" (Visited/Played POIs).

### שלב 3: ממשק (UI Integration)
1.  בניית הקומפוננטה `VoiceGuidePlayer`.
2.  שילוב ב-`RouteOverview` או במסך המפה הראשי.

### שלב 4: אופטימיזציה (Optimization)
1.  הוספת מנגנון Pre-loading לאודיו (טעינת הנקודה הבאה ברקע).
2.  טיפול במקרי קצה (ניתוק אינטרנט, הפסקה לשיחת טלפון).

## 5. חלוקת אחריות (Who is Responsible)

*   **אחראי יישום ראשי (Lead Implementation):**
    *   **תפקיד:** Voice AI Specialist (הסוכן המתמחה בפיתוח Voice AI).
    *   **משאבים:** ייעזר בתיקיית הכישורים `.agent/skills/skills/voice-ai-development` למימוש Best Practices של ניגון אודיו וסטרימינג.
    *   **משימה מיידית:** הקמת ה-`AudioProvider` וחיבורו ל-Gemini Service.

*   **אחראי ממשק וחוויה (Frontend/UX):**
    *   **תפקיד:** Frontend Developer (אתה/אני בשלב הנוכחי).
    *   **משימה:** עיצוב ושילוב הנגן במסך המפה בצורה לא פולשנית.

---
**הערה חשובה להמשך:** יש לוודא שקיימת הרשאת מיקום פעילה ושהמשתמש אישר "ניגון סאונד" (User Interaction) בתחילת המסלול כדי לאפשר ניגון אוטומטי בהמשך.
